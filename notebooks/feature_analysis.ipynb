{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Fake News Detection - Feature Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook analyzes the features extracted from text data for fake news detection. We'll explore:\\n\",\n",
    "    \"1. Feature extraction and visualization\\n\",\n",
    "    \"2. Feature importance analysis\\n\",\n",
    "    \"3. Model performance comparison\\n\",\n",
    "    \"4. Correlation analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"sys.path.append(os.path.abspath('../src'))\\n\",\n",
    "    \"\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.metrics import classification_report, confusion_matrix\\n\",\n",
    "    \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestClassifier\\n\",\n",
    "    \"from sklearn.decomposition import PCA\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler\\n\",\n",
    "    \"\\n\",\n",
    "    \"from data_processor import FakeNewsDataset\\n\",\n",
    "    \"from features import FeatureExtractor\\n\",\n",
    "    \"from models import EnhancedClassifier\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Load and Prepare Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"dataset = FakeNewsDataset('../data')\\n\",\n",
    "    \"texts = dataset.texts\\n\",\n",
    "    \"labels = dataset.labels\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Total samples: {len(texts)}\\\")\\n\",\n",
    "    \"print(f\\\"Fake news samples: {sum(labels)}\\\")\\n\",\n",
    "    \"print(f\\\"Real news samples: {len(labels) - sum(labels)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Extract Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"feature_extractor = FeatureExtractor()\\n\",\n",
    "    \"features = feature_extractor.extract_features(texts)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Extracted features:\\\")\\n\",\n",
    "    \"for feature_name, feature_values in features.items():\\n\",\n",
    "    \"    print(f\\\"- {feature_name}: {len(feature_values)} samples\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Feature Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def plot_feature_distribution(feature_name, values, labels):\\n\",\n",
    "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"    sns.histplot(data=pd.DataFrame({\\n\",\n",
    "    \"        feature_name: values,\\n\",\n",
    "    \"        'label': ['Fake' if l == 1 else 'Real' for l in labels]\\n\",\n",
    "    \"    }), x=feature_name, hue='label', kde=True)\\n\",\n",
    "    \"    plt.title(f'Distribution of {feature_name}')\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"for feature_name, feature_values in features.items():\\n\",\n",
    "    \"    plot_feature_distribution(feature_name, feature_values, labels)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Feature Importance Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"X = np.column_stack(list(features.values()))\\n\",\n",
    "    \"y = np.array(labels)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\",\n",
    "    \"\\n\",\n",
    "    \"rf = RandomForestClassifier(n_estimators=100, random_state=42)\\n\",\n",
    "    \"rf.fit(X_train, y_train)\\n\",\n",
    "    \"\\n\",\n",
    "    \"feature_importance = pd.DataFrame({\\n\",\n",
    "    \"    'feature': list(features.keys()),\\n\",\n",
    "    \"    'importance': rf.feature_importances_\\n\",\n",
    "    \"}).sort_values('importance', ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 6))\\n\",\n",
    "    \"sns.barplot(data=feature_importance, x='importance', y='feature')\\n\",\n",
    "    \"plt.title('Feature Importance')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Correlation Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"feature_df = pd.DataFrame(features)\\n\",\n",
    "    \"correlation_matrix = feature_df.corr()\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(12, 10))\\n\",\n",
    "    \"sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0)\\n\",\n",
    "    \"plt.title('Feature Correlation Matrix')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Dimensionality Reduction and Visualization\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"scaler = StandardScaler()\\n\",\n",
    "    \"X_scaled = scaler.fit_transform(X)\\n\",\n",
    "    \"\\n\",\n",
    "    \"pca = PCA(n_components=2)\\n\",\n",
    "    \"X_pca = pca.fit_transform(X_scaled)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.figure(figsize=(10, 8))\\n\",\n",
    "    \"sns.scatterplot(\\n\",\n",
    "    \"    x=X_pca[:, 0],\\n\",\n",
    "    \"    y=X_pca[:, 1],\\n\",\n",
    "    \"    hue=['Fake' if l == 1 else 'Real' for l in labels],\\n\",\n",
    "    \"    alpha=0.6\\n\",\n",
    "    \")\\n\",\n",
    "    \"plt.title('PCA of Features')\\n\",\n",
    "    \"plt.xlabel('First Principal Component')\\n\",\n",
    "    \"plt.ylabel('Second Principal Component')\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Model Performance Comparison\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"def evaluate_model(model, X_train, X_test, y_train, y_test):\\n\",\n",
    "    \"    model.fit(X_train, y_train)\\n\",\n",
    "    \"    y_pred = model.predict(X_test)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(classification_report(y_test, y_pred))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    plt.figure(figsize=(8, 6))\\n\",\n",
    "    \"    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\\n\",\n",
    "    \"    plt.title('Confusion Matrix')\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Random Forest Classifier:\\\")\\n\",\n",
    "    \"evaluate_model(rf, X_train, X_test, y_train, y_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nEnhanced Classifier:\\\")\\n\",\n",
    "    \"enhanced_model = EnhancedClassifier()\\n\",\n",
    "    \"evaluate_model(enhanced_model, X_train, X_test, y_train, y_test)\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.13.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
